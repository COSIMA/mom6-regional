{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regional Tasmanian domain forced by JRA55-do reanalysis and ACCESS-OM2-01 model output\n",
    "\n",
    "### Note: This example requires access to [NCI's Gadi HPC system](https://nci.org.au/our-systems/hpc-systems)\n",
    "\n",
    "**Ensure you have access to the relevant NCI projects to access the data listed below. If needed, apply via [mancini](https://my.nci.org.au/mancini).**\n",
    "\n",
    "## What does this notebook do?\n",
    "This notebook is designed to set you up with a working MOM6 regional configuration. First, try and get it running with our default Tasmania case, then you can clone the notebook and modify for your region of interest. \n",
    "\n",
    "Input Type | Source | Location on NCI\n",
    "---|---|---\n",
    "Surface | [JRA55-do surface forcing](https://climate.mri-jma.go.jp/pub/ocean/JRA55-do/) | `/g/data/ik11`\n",
    "Ocean | [ACCESS-OM2-01](https://github.com/COSIMA/access-om2) |  `/g/data/ik11`  \n",
    "Bathymetry | [GEBCO](https://www.gebco.net/data_and_products/gridded_bathymetry_data/) | `/g/data/ik11`\n",
    "\n",
    "Additionally, you'll need access to `/g/data/x77/` if you want to use the same executable using the latest FMS build (a good idea for troubleshooting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use your own version of the `regional_mom6` package, clone the entire [github repository](https://github.com/COSIMA/regional-mom6)\n",
    "on your machine and set the regional-mom6 path using the `os` library, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/g/data/v45/nc3020/dhruvs-regional-mom6/\")\n",
    "\n",
    "import regional_mom6 as rmom6\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a dask client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## What does the `regional_mom6` package do?\n",
    "\n",
    "Setting up a regional model in MOM6 can be a pain. The goal of this package is that users should spend their debugging time fixing a model that's running and doing weird things, rather than puzzling over a model that won't even start.\n",
    "\n",
    "In running this notebook, you'll hopefully have a running MOM6 regional model. There will still be a lot of fiddling to do with the `MOM_input` file to make sure that the parameters are set up right for your domain, and you might want to manually edit some of the input files. *But*, this package should help you bypass most of the woes of regridding, encoding and understanding the arcane arts of the MOM6 boundary segment files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does this notebook do?\n",
    "\n",
    "This notebook demonstrates how to set up a regional domain using the package. By the end you should have a running MOM6 experiment on the domain of your choice. To make a stable test case:\n",
    "\n",
    "* Avoid any regions with ice\n",
    "* Avoid regions near the north pole\n",
    "* Although the default configuration is meant to be repeat-year forced (RYF), the calendar and encoding will need fixing to run longer than a year\n",
    "\n",
    "\n",
    "Input Type | Source\n",
    "---|---\n",
    "Surface | JRA55-do\n",
    "Ocean | ACCESS-OM2-01\n",
    "Bathymetry | Gebco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Your personal environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scratch = \"/scratch/v45/nc3020\"\n",
    "gdata = \"/g/data/v45/nc3020\"\n",
    "home = \"/home/552/nc3020\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Choose our domain, define workspace paths\n",
    "\n",
    "To make sure that things are working I'd recommend starting with the default example defined below. If this runs ok, then change to a domain of your choice and hopefully it runs ok too! If not, check the [README](https://github.com/COSIMA/regional-mom6/blob/main/README.md) and [documentation](https://regional-mom6.readthedocs.io/) for troubleshooting tips.\n",
    "\n",
    "You can log in and use [this GUI](https://data.marine.copernicus.eu/product/GLOBAL_MULTIYEAR_PHY_001_030/download) to find the lat/lon of your domain and copy paste below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expt_name = \"tassie-access-om2-forced\"\n",
    "\n",
    "latitude_extent = [-48, -38.95]\n",
    "longitude_extent = [143, 150]\n",
    "\n",
    "date_range = [\"2003-01-01 00:00:00\", \"2003-01-05 00:00:00\"]\n",
    "\n",
    "## Place where all your input files go\n",
    "input_dir = f\"{scratch}/regional_mom6_configs/{expt_name}/\"\n",
    "\n",
    "## Directory where you'll run the experiment from\n",
    "run_dir = f\"{home}/mom6_rundirs/{expt_name}/\"\n",
    "\n",
    "## Directory where fre tools are stored\n",
    "toolpath_dir = \"/home/157/ahg157/repos/mom5/src/tools/\" ## Compiled tools needed for construction of mask tables\n",
    "\n",
    "## Directory where ocean model cut-outs go before processing\n",
    "tmp_dir = f\"{gdata}/{expt_name}\"\n",
    "\n",
    "## if directories don't exist, create them\n",
    "for path in(run_dir, tmp_dir, input_dir):\n",
    "    os.makedirs(str(path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare ocean forcing data\n",
    "\n",
    "We need to cut out our ocean forcing. The pipeline expects an initial condition and one time-dependent segment per non-land boundary. Naming convention is `\"east_unprocessed\"` and `\"ic_unprocessed\"` for initial condition. The following provides an example for cutting out the necessary forcing files from an ocean model. It's hardcoded to pull data from a Repeat-Year Forced ACCESS-OM2-01 database, but you should be able to recycle parts of the code to cut out data from a dataset of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: this is hardcoded for the year of 1990, which corresponds to output files `1077`-`1082`. If you want to modify, you'll need to choose the right path to the year of your choice, or use the [COSIMA cookbook](https://cosima-cookbook.readthedocs.io/) to locate your data files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Cut out 3 months of forcing from 2003\n",
    "om2_input = xr.open_mfdataset(\n",
    "    f\"/g/data/ik11/outputs/access-om2-01/01deg_jra55v13_ryf9091/output1077/ocean/ocean_daily*\",\n",
    "    parallel=True, chunks='auto')[[\"u\", \"v\", \"salt\", \"temp\", \"eta_t\"]].sel(\n",
    "        yu_ocean = slice(latitude_extent[0] - 0.2, latitude_extent[1] + 0.2),\n",
    "        yt_ocean = slice(latitude_extent[0] - 0.2, latitude_extent[1] + 0.2)).isel(time = slice(0, 5))\n",
    "\n",
    "## Cut out initial condition and save\n",
    "ic = om2_input.isel(time = 0)\n",
    "\n",
    "## `longitude_slicer` handles seams in longitude and different grid and ensures that the output matches our 'longitude_extent'\n",
    "ic = rmom6.longitude_slicer(ic, [longitude_extent[0], longitude_extent[1]], [\"xu_ocean\", \"xt_ocean\"])\n",
    "ic.to_netcdf(tmp_dir + \"/ic_unprocessed.nc\")\n",
    "\n",
    "## Cut out East and West segments. Does lat slice first then uses `longitude_slicer` for lon slice\n",
    "eastwest = om2_input.sel(    \n",
    "    yu_ocean = slice(latitude_extent[0] - 0.2, latitude_extent[1] + 0.2),\n",
    "    yt_ocean = slice(latitude_extent[0] - 0.2, latitude_extent[1] + 0.2)\n",
    ")\n",
    "rmom6.longitude_slicer(eastwest, [longitude_extent[1], longitude_extent[1]], [\"xu_ocean\", \"xt_ocean\"]).to_netcdf(tmp_dir + \"/east_unprocessed.nc\")\n",
    "rmom6.longitude_slicer(eastwest, [longitude_extent[0], longitude_extent[0]], [\"xu_ocean\", \"xt_ocean\"]).to_netcdf(tmp_dir + \"/west_unprocessed.nc\")\n",
    "\n",
    "## Cut out North and South segments\n",
    "northsouth = rmom6.longitude_slicer(om2_input, [longitude_extent[0], longitude_extent[1]], [\"xu_ocean\", \"xt_ocean\"])\n",
    "northsouth.sel(\n",
    "    yu_ocean = slice(latitude_extent[1] - 0.2, latitude_extent[1] + 0.2),\n",
    "    yt_ocean = slice(latitude_extent[1] - 0.2, latitude_extent[1] + 0.2)\n",
    ").to_netcdf(tmp_dir + \"/north_unprocessed.nc\")\n",
    "northsouth.sel(\n",
    "    yu_ocean = slice(latitude_extent[0] - 0.2, latitude_extent[0] + 0.2),\n",
    "    yt_ocean = slice(latitude_extent[0] - 0.2, latitude_extent[0] + 0.2)\n",
    ").to_netcdf(tmp_dir + \"/south_unprocessed.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make experiment object\n",
    "The `regional_mom6.experiment` contains the regional domain basics, and also generates the horizontal and vertical grids, `hgrid` and `vgrid` respectively, and sets up the directory structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expt = rmom6.experiment(\n",
    "    longitude_extent = longitude_extent,\n",
    "    latitude_extent = latitude_extent,\n",
    "    date_range = date_range,\n",
    "    resolution = 0.05,\n",
    "    number_vertical_layers = 75,\n",
    "    layer_thickness_ratio = 10,\n",
    "    depth = 4500,\n",
    "    mom_run_dir = run_dir,\n",
    "    mom_input_dir = input_dir,\n",
    "    toolpath_dir = toolpath_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now access the horizontal and vertical grid of the regional configuration via `expt.hgrid` and `expt.vgrid` respectively.\n",
    "\n",
    "Plotting the vertical grid with `marker = '.'` lets you see the spacing. You can use `numpy.diff` to compute the vertical spacings, e.g.,\n",
    "```python\n",
    "import numpy as np\n",
    "np.diff(expt.vgrid.zl).plot(marker = '.')\n",
    "```\n",
    "shows you the vertical spacing profile.\n",
    "\n",
    "### Modular workflow!\n",
    "\n",
    "After constructing your `expt` object, if you don't like the default `hgrid` and `vgrid` you can simply modify and then save them back into the `expt` object. However, you'll then also need to save them to disk again. For example:\n",
    "\n",
    "```python\n",
    "new_hgrid = xr.open_dataset(input_dir + \"/hgrid.nc\")\n",
    "```\n",
    "Modify `new_hgrid`, ensuring that _all metadata_ is retained to keep MOM6 happy. Then, save your changes\n",
    "\n",
    "```python\n",
    "expt.hgrid = new_hgrid\n",
    "\n",
    "expt.hgrid.to_netcdf(input_dir + \"/hgrid.nc\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Set up bathymetry\n",
    "\n",
    "Similarly to ocean forcing, we point the experiment's `setup_bathymetry` method at the location of the file of choice and also provide the variable names. We don't need to preprocess the bathymetry since it is simply a two-dimensional field and is easier to deal with. Afterwards you can inspect `expt.bathymetry` to have a look at the regional domain.\n",
    "\n",
    "After running this cell, your input directory will contain other bathymetry-related things like the ocean mosaic and mask table too. The mask table defaults to a 10x10 layout and can be modified later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expt.setup_bathymetry(\n",
    "    bathymetry_path='/g/data/ik11/inputs/GEBCO_2022/GEBCO_2022.nc',\n",
    "    longitude_coordinate_name='lon',\n",
    "    latitude_coordinate_name='lat',\n",
    "    vertical_coordinate_name='elevation',\n",
    "    minimum_layers=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out your domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expt.bathymetry.depth.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 5: Handle the ocean forcing - where the magic happens\n",
    "\n",
    "This cuts out and interpolates the initial condition as well as all boundaries (unless you don't pass it boundaries).\n",
    "\n",
    "The dictionary maps the MOM6 variable names to what they're called in your ocean input file. Notice how the horizontal dimensions are `xt_ocean`, `yt_ocean`, `xu_ocean`, `yu_ocean` in ACCESS-OM2-01 versus `xh`, `yh`, `xq`, and `yq` in MOM6. This is because ACCESS-OM2-01 is on a `B` grid, so we need to differentiate between `q` and `t` points. \n",
    "\n",
    "If one of your segments is land, you can delete its string from the 'boundaries' list. You'll need to update `MOM_input` to reflect this though so it knows how many segments to look for, and their orientations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a mapping from the MOM5 B grid variables and dimensions to the MOM6 C grid ones\n",
    "ocean_varnames = {\"time\": \"time\",\n",
    "                  \"yh\": \"yt_ocean\",\n",
    "                  \"xh\": \"xt_ocean\",\n",
    "                  \"xq\": \"xu_ocean\",\n",
    "                  \"yq\": \"yu_ocean\",\n",
    "                  \"zl\": \"st_ocean\",\n",
    "                  \"eta\": \"eta_t\",\n",
    "                  \"u\": \"u\",\n",
    "                  \"v\": \"v\",\n",
    "                  \"tracers\": {\"salt\": \"salt\", \"temp\": \"temp\"}\n",
    "                  }\n",
    "\n",
    "# Set up the initial condition\n",
    "expt.initial_condition(\n",
    "    tmp_dir + '/ic_unprocessed.nc', # directory where the unprocessed initial condition is stored, as defined earlier\n",
    "    ocean_varnames,\n",
    "    arakawa_grid=\"B\"\n",
    "    )\n",
    "\n",
    "# Now iterate through our four boundaries \n",
    "for i, orientation in enumerate([\"south\", \"north\", \"west\", \"east\"]):\n",
    "    expt.rectangular_boundary(\n",
    "        tmp_dir + '/' + orientation + \"_unprocessed.nc\",\n",
    "        ocean_varnames,\n",
    "        orientation,    # Needs to know the cardinal direction of the boundary\n",
    "        i + 1,          # Just a number to identify the boundary. Indexes from 1 \n",
    "        arakawa_grid=\"B\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 Run the FRE tools\n",
    "\n",
    "This is just a wrapper for the FRE tools needed to make the mosaics and masks for the experiment. The only thing you need to tell it is the processor layout. In this case we're saying that we want a 10 by 10 grid of 100 processors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expt.FRE_tools(layout = (10, 10)) ## Here the tuple defines the processor layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Modify the default input directory to make a (hopefully) runnable configuration out of the box\n",
    "\n",
    "This step copies the default directory, and modifies the `MOM_layout` files to match your experiment by inserting the right number of x,y points and cpu layout. If you use Payu to run MOM6, set the `using_payu` flag to `True` and an example `config.yaml` file will be copied to your run directory. This still needs to be modified manually to work with your projects, executable etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expt.setup_run_directory(surface_forcing = \"jra\", using_payu = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Run your model!\n",
    "\n",
    "To do this, navigate to your run directory in terminal. If you're working on NCI, you can run your model via:\n",
    "\n",
    "```\n",
    "module load conda/analysis3\n",
    "payu setup -f\n",
    "payu run -f\n",
    "```\n",
    "\n",
    "By default `input.nml` is set to only run for 5 days as a test. If this is successful, you can modify this file to then run for longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 and beyond: Fiddling, troubleshooting and fine tuning\n",
    "\n",
    "Hopefully your model is running. If not, the first thing you should do is reduce the timestep. You can do this by adding `#override DT=XXXX` to your `MOM_override` file. \n",
    "\n",
    "If there's strange behaviour on your boundaries, you could play around with the `nudging timescale` (an example is already included in the `MOM_override` file). Sometimes, if your boundary has a lot going on (like all of the eddies spinning off the western boundary currents or off the Antarctic Circumpolar current), it can be hard to avoid these edge effects. This is because the chaotic, submesoscale structures developed within the regional domain won't match those at the boundary.\n",
    "\n",
    "Another thing that can go wrong is little bays creating non-advective cells at your boundaries. Keep an eye out for tiny bays where one side is taken up by a boundary segment. You can either fill them in manually, or move your boundary slightly to avoid them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-24.01] *",
   "language": "python",
   "name": "conda-env-analysis3-24.01-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
