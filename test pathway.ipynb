{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import cycle\n",
    "import os\n",
    "import dask.array as da\n",
    "import dask.bag as db\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import subprocess\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from importlib import reload\n",
    "os.chdir(\"/home/149/ab8992/cosima_regional/mom6-regional-scripts\")\n",
    "import regional_library as ml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test run! See if we get a working model from the experiment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ml)\n",
    "\n",
    "## Choose your coordinates and the name of your experiment\n",
    "yextent = [-48,-38.95]\n",
    "xextent = [-217 + 360, -210 + 360]\n",
    "expt_name = \"test-pathway\"\n",
    "\n",
    "pwd = \"$KQ%QqFxjSSbE2\"\n",
    "usr = \"abarnes\"\n",
    "\n",
    "\n",
    "daterange = [\"2015-01-01 00:00:00\", \"2015-01-31 00:00:00\"]\n",
    "\n",
    "## Place where all your input files go\n",
    "inputdir = f\"/scratch/v45/ab8992/mom6/regional_configs/{expt_name}/\"\n",
    "\n",
    "## Directory where you'll run the experiment from\n",
    "rundir = f\"/home/149/ab8992/mom6_rundirs/{expt_name}/\"\n",
    "\n",
    "## Directory where raw downloads go before processing\n",
    "tmpdir = f\"/scratch/v45/ab8992/reanalysis_tmp/reanalysis-small/\"\n",
    "\n",
    "## Directory where fre tools are stored\n",
    "toolpath = \"/home/157/ahg157/repos/mom5/src/tools/\" ## Compiled tools needed for construction of mask tables\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First make an experiment object\n",
    "This keeps track of your domain basics, as well as generating the hgrid, vgrid and setting up the folder structures. \n",
    "\n",
    "Sanity check: After running you a sensible hgrid and vgrind should appear in your input directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRE TOOLS: Make hgrid \n",
      "\n",
      " CompletedProcess(args=['/home/157/ahg157/repos/mom5/src/tools/make_hgrid/make_hgrid', '--grid_type', 'from_file', '--my_grid_file', 'grid.nc'], returncode=0)\n",
      "NOTE from make_solo_mosaic: there are 0 contacts (align-contact)\n",
      "congradulation: You have successfully run make_solo_mosaic\n",
      "FRE TOOLS: Make solo mosaic\n",
      "\n",
      "\n",
      "CompletedProcess(args=['/home/157/ahg157/repos/mom5/src/tools/make_solo_mosaic/make_solo_mosaic', '--num_tiles', '1', '--dir', '.', '--mosaic_name', 'ocean_mosaic', '--tile_file', 'hgrid.nc'], returncode=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link '/home/149/ab8992/mom6_rundirs/test-pathway//inputdir/test-pathway': File exists\n",
      "ln: failed to create symbolic link '/scratch/v45/ab8992/mom6/regional_configs/test-pathway//rundir/test-pathway': File exists\n"
     ]
    }
   ],
   "source": [
    "expt = ml.experiment(\n",
    "    xextent,\n",
    "    yextent,\n",
    "    0.0333,  ## Resolution\n",
    "    75,      ## #zlayers\n",
    "    20,       ## dz ratio\n",
    "    3000,    ## Max depth of ocean\n",
    "    rundir,\n",
    "    inputdir,\n",
    "    toolpath\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, handle the ocean forcing.\n",
    "\n",
    "This cuts out and interpolates the initial condition as well as all boundaries (unless you don't pass it boundaries).\n",
    "\n",
    "If you haven't used the script that pulls down the Glorys data, be sure to cut out your boundaries and name them like \"north_segment_unprocessed\", and your IC like \"ic_segment_unprocessed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = expt.ocean_forcing(\n",
    "    tmpdir,  ## Path to ocean foring files\n",
    "    {\"time\":\"time\",\"y\":\"latitude\",\"x\":\"longitude\",\n",
    "     \"zl\":\"depth\",\"eta\":\"zos\",\"u\":\"uo\",\"v\":\"vo\",\n",
    "     \"tracers\":{\"salt\":\"so\",\"temp\":\"thetao\"}},\n",
    "    boundaries = [\"south\",\"north\",\"west\",\"east\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt.make_bathymetry(\n",
    "    '/g/data/ik11/inputs/GEBCO_2022/GEBCO_2022.nc',\n",
    "    {\"xh\":\"lon\",\"yh\":\"lat\",\"elevation\":\"elevation\"},\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to handle:\n",
    "* Forcing files that have negative longitudes. Should ensure that xextent always means the same thing\n",
    "* Have all of my compiled fre tools together in the same folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is stuff copied from the old notebook that's not in pipeline. \n",
    "* Runoff\n",
    "* Make mask\n",
    "* copy default run directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regional_model_scripts import regrid_runoff\n",
    "runoff_path = \"/g/data/ik11/inputs/JRA-55/RYF/v1-3/RYF.runoff_all.1990_1991.nc\"\n",
    "\n",
    "regrid_runoff(inputdir + \"ocean_mask.nc\",\n",
    "    inputdir + \"hgrid.nc\",\n",
    "    runoff_path,\n",
    "    inputdir + \"runoff_regrid.nc\",\n",
    "    np.array(xextent) - np.array([180,180]),\n",
    "    yextent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the default input directory to make a (hopefully) runnable configuration out of the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link '/home/149/ab8992/mom6_rundirs/test-pathway//inputdir/test-pathway': File exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='cp vcoord.nc /scratch/v45/ab8992/mom6/regional_configs/test-pathway/', returncode=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(f\"cp default_rundir/* {rundir}\",shell = True)\n",
    "subprocess.run(f\"ln -s {inputdir} {rundir}/inputdir\",shell=True)\n",
    "\n",
    "hgrid = xr.open_dataset(f\"{inputdir}/hgrid.nc\")\n",
    "\n",
    "## Get mask table information\n",
    "ncpus = 100\n",
    "mask_table = None\n",
    "for i in os.listdir(f\"{inputdir}\"):\n",
    "    if \"mask_table\" in i:\n",
    "        mask_table = i\n",
    "        a = mask_table.split(\".\")[1]\n",
    "        b = mask_table.split(\".\")[2].split(\"x\")\n",
    "        ncpus = int(b[0]) * int(b[1]) - int(a)\n",
    "\n",
    "\n",
    "## Modify MOM_input\n",
    "inputfile = open(f\"{rundir}/MOM_input\",'r')\n",
    "lines = inputfile.readlines()\n",
    "inputfile.close()\n",
    "for i in range(len(lines)):\n",
    "    if \"MASKTABLE\" in lines[i]:\n",
    "        if mask_table != None:\n",
    "            lines[i] = f'MASKTABLE = \"{mask_table}\"\\n'\n",
    "        else:\n",
    "            lines[i] = \"# MASKTABLE = no mask table\"\n",
    "    if \"NIGLOBAL\" in lines[i]: \n",
    "        # lines[i] = f\"NIGLOBAL = {str(x_indices_centre[1] - x_indices_centre[0])}\\n\"\n",
    "        lines[i] = f\"NIGLOBAL = {hgrid.nx.shape[0]//2}\\n\"\n",
    "\n",
    "        \n",
    "    if \"NJGLOBAL\" in lines[i]:\n",
    "        # lines[i] = f\"NJGLOBAL = {str(y_indices_centre[1] - y_indices_centre[0])}\\n\"\n",
    "        lines[i] = f\"NJGLOBAL = {hgrid.ny.shape[0]//2}\\n\"\n",
    "\n",
    "        \n",
    "inputfile = open(f\"{rundir}/MOM_input\",'w')\n",
    "\n",
    "inputfile.writelines(lines)\n",
    "inputfile.close()\n",
    "\n",
    "## Modify SIS_input\n",
    "inputfile = open(f\"{rundir}/SIS_input\",'r')\n",
    "lines = inputfile.readlines()\n",
    "inputfile.close()\n",
    "for i in range(len(lines)):\n",
    "    if \"MASKTABLE\" in lines[i]:\n",
    "        lines[i] = f'MASKTABLE = \"{mask_table}\"\\n'\n",
    "    if \"NIGLOBAL\" in lines[i]:\n",
    "        # lines[i] = f\"NIGLOBAL = {str(x_indices_centre[1] - x_indices_centre[0])}\\n\"\n",
    "        lines[i] = f\"NIGLOBAL = {hgrid.nx.shape[0]//2}\\n\"\n",
    "        \n",
    "    if \"NJGLOBAL\" in lines[i]:\n",
    "        # lines[i] = f\"NJGLOBAL = {str(y_indices_centre[1] - y_indices_centre[0])}\\n\"\n",
    "        lines[i] = f\"NJGLOBAL = {hgrid.ny.shape[0]//2}\\n\"\n",
    "        \n",
    "inputfile = open(f\"{rundir}/SIS_input\",'w')\n",
    "inputfile.writelines(lines)\n",
    "inputfile.close()\n",
    "\n",
    "## Modify config.yaml \n",
    "inputfile = open(f\"{rundir}/config.yaml\",'r')\n",
    "lines = inputfile.readlines()\n",
    "inputfile.close()\n",
    "for i in range(len(lines)):\n",
    "    if \"ncpus\" in lines[i]:\n",
    "        lines[i] = f'ncpus: {str(ncpus)}\\n'\n",
    "    if \"jobname\" in lines[i]:\n",
    "        lines[i] = f\"jobname: mom6_{expt_name}\\n\"\n",
    "        \n",
    "    if \"input:\" in lines[i]:\n",
    "        lines[i + 1] = f\"    - {inputdir}\\n\"\n",
    "        \n",
    "inputfile = open(f\"{rundir}/config.yaml\",'w')\n",
    "inputfile.writelines(lines)\n",
    "inputfile.close()\n",
    "\n",
    "subprocess.run(f\"cp vcoord.nc {inputdir}\",shell=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing access om2 input below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRE TOOLS: Make hgrid \n",
      "\n",
      " CompletedProcess(args=['/home/157/ahg157/repos/mom5/src/tools/make_hgrid/make_hgrid', '--grid_type', 'from_file', '--my_grid_file', 'grid.nc'], returncode=0)\n",
      "NOTE from make_solo_mosaic: there are 0 contacts (align-contact)\n",
      "congradulation: You have successfully run make_solo_mosaic\n",
      "FRE TOOLS: Make solo mosaic\n",
      "\n",
      "\n",
      "CompletedProcess(args=['/home/157/ahg157/repos/mom5/src/tools/make_solo_mosaic/make_solo_mosaic', '--num_tiles', '1', '--dir', '.', '--mosaic_name', 'ocean_mosaic', '--tile_file', 'hgrid.nc'], returncode=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link '/home/149/ab8992/mom6_rundirs/om2-input//inputdir/om2-input': File exists\n",
      "ln: failed to create symbolic link '/scratch/v45/ab8992/mom6/regional_configs/om2-input//rundir/om2-input': File exists\n"
     ]
    }
   ],
   "source": [
    "reload(ml)\n",
    "\n",
    "## Choose your coordinates and the name of your experiment\n",
    "yextent = [-48,-38.95]\n",
    "xextent = [-217 + 360, -210 + 360]\n",
    "expt_name = \"om2-input\"\n",
    "\n",
    "pwd = \"$KQ%QqFxjSSbE2\"\n",
    "usr = \"abarnes\"\n",
    "\n",
    "\n",
    "daterange = [\"1901-01-01 00:00:00\", \"1901-01-31 00:00:00\"]\n",
    "\n",
    "## Place where all your input files go\n",
    "inputdir = f\"/scratch/v45/ab8992/mom6/regional_configs/{expt_name}/\"\n",
    "\n",
    "## Directory where you'll run the experiment from\n",
    "rundir = f\"/home/149/ab8992/mom6_rundirs/{expt_name}/\"\n",
    "\n",
    "## Directory where raw downloads go before processing\n",
    "tmpdir = f\"/scratch/v45/ab8992/mom6/regional_configs/{expt_name}/rawboundaries\"\n",
    "\n",
    "## Directory where fre tools are stored\n",
    "toolpath = \"/home/157/ahg157/repos/mom5/src/tools/\" ## Compiled tools needed for construction of mask tables\n",
    "\n",
    "expt = ml.experiment(\n",
    "    xextent,\n",
    "    yextent,\n",
    "    0.0333,  ## Resolution\n",
    "    75,      ## #zlayers\n",
    "    20,       ## dz ratio\n",
    "    3000,    ## Max depth of ocean\n",
    "    rundir,\n",
    "    inputdir,\n",
    "    toolpath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "om2_input = xr.open_mfdataset(\"/g/data/ik11/outputs/access-om2-01/01deg_jra55v13_ryf9091/output1077/ocean/ocean_daily*\",decode_times = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Values of an IndexVariable are immutable and can not be modified inplace",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m xextent[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m360\u001b[39m \u001b[39m## Access om2 is on -270 to 90 grid. Slice out and then change coords after\u001b[39;00m\n\u001b[1;32m      4\u001b[0m ic \u001b[39m=\u001b[39m om2_input[[\u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mv\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msalt\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mtemp\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39meta_t\u001b[39m\u001b[39m\"\u001b[39m]]\u001b[39m.\u001b[39msel(\n\u001b[1;32m      5\u001b[0m     xt_ocean \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m(xextent[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m0.2\u001b[39m,xextent[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m0.2\u001b[39m),\n\u001b[1;32m      6\u001b[0m     yt_ocean \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m(yextent[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m0.2\u001b[39m,yextent[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m0.2\u001b[39m),    \n\u001b[1;32m      7\u001b[0m     xu_ocean \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m(xextent[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m0.2\u001b[39m,xextent[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m0.2\u001b[39m),\n\u001b[1;32m      8\u001b[0m     yu_ocean \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m(yextent[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m0.2\u001b[39m,yextent[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m0.2\u001b[39m)\n\u001b[1;32m      9\u001b[0m )\u001b[39m.\u001b[39misel(time \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m ic[\u001b[39m\"\u001b[39m\u001b[39mxu_ocean\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m360\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[39m# .to_netcdf(tmpdir + \"/ic_unprocessed\")\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[39m# om2_input[[\"u\",\"v\",\"salt\",\"temp\",\"eta_t\"]].sel(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m#     yt_ocean = slice(yextent[0] - 0.2,yextent[0] + 0.2)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m# ).to_netcdf(tmpdir + \"/south_unprocessed\")\u001b[39;00m\n",
      "File \u001b[0;32m/g/data/hh5/public/apps/miniconda3/envs/analysis3-22.10/lib/python3.9/site-packages/xarray/core/_typed_ops.py:287\u001b[0m, in \u001b[0;36mDataArrayOpsMixin.__iadd__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iadd__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m--> 287\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inplace_binary_op(other, operator\u001b[39m.\u001b[39;49miadd)\n",
      "File \u001b[0;32m/g/data/hh5/public/apps/miniconda3/envs/analysis3-22.10/lib/python3.9/site-packages/xarray/core/dataarray.py:4380\u001b[0m, in \u001b[0;36mDataArray._inplace_binary_op\u001b[0;34m(self, other, f)\u001b[0m\n\u001b[1;32m   4378\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   4379\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoords\u001b[39m.\u001b[39m_merge_inplace(other_coords):\n\u001b[0;32m-> 4380\u001b[0m         f(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvariable, other_variable)\n\u001b[1;32m   4381\u001b[0m \u001b[39mexcept\u001b[39;00m MergeError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m   4382\u001b[0m     \u001b[39mraise\u001b[39;00m MergeError(\n\u001b[1;32m   4383\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAutomatic alignment is not supported for in-place operations.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4384\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider aligning the indices manually or using a not-in-place operation.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4385\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/pydata/xarray/issues/3910 for more explanations.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4386\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "File \u001b[0;32m/g/data/hh5/public/apps/miniconda3/envs/analysis3-22.10/lib/python3.9/site-packages/xarray/core/_typed_ops.py:477\u001b[0m, in \u001b[0;36mVariableOpsMixin.__iadd__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iadd__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m--> 477\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inplace_binary_op(other, operator\u001b[39m.\u001b[39;49miadd)\n",
      "File \u001b[0;32m/g/data/hh5/public/apps/miniconda3/envs/analysis3-22.10/lib/python3.9/site-packages/xarray/core/variable.py:3061\u001b[0m, in \u001b[0;36mIndexVariable._inplace_binary_op\u001b[0;34m(self, other, f)\u001b[0m\n\u001b[1;32m   3060\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_inplace_binary_op\u001b[39m(\u001b[39mself\u001b[39m, other, f):\n\u001b[0;32m-> 3061\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   3062\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mValues of an IndexVariable are immutable and can not be modified inplace\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3063\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Values of an IndexVariable are immutable and can not be modified inplace"
     ]
    }
   ],
   "source": [
    "xextent[0] -= 360\n",
    "xextent[1] -= 360 ## Access om2 is on -270 to 90 grid. Slice out and then change coords after\n",
    "\n",
    "ic = om2_input[[\"u\",\"v\",\"salt\",\"temp\",\"eta_t\"]].sel(\n",
    "    xt_ocean = slice(xextent[0] - 0.2,xextent[1] + 0.2),\n",
    "    yt_ocean = slice(yextent[0] - 0.2,yextent[1] + 0.2),    \n",
    "    xu_ocean = slice(xextent[0] - 0.2,xextent[1] + 0.2),\n",
    "    yu_ocean = slice(yextent[0] - 0.2,yextent[1] + 0.2)\n",
    ").isel(time = 0)\n",
    "\n",
    "ic[\"xu_ocean\"] += 360\n",
    "\n",
    "# .to_netcdf(tmpdir + \"/ic_unprocessed\")\n",
    "\n",
    "# om2_input[[\"u\",\"v\",\"salt\",\"temp\",\"eta_t\"]].sel(\n",
    "#     xt_ocean = slice(xextent[1] - 0.2,xextent[1] + 0.2),\n",
    "#     yt_ocean = slice(yextent[0] - 0.2,yextent[1] + 0.2)\n",
    "# ).to_netcdf(tmpdir + \"/east_unprocessed\")\n",
    "\n",
    "# om2_input[[\"u\",\"v\",\"salt\",\"temp\",\"eta_t\"]].sel(\n",
    "#     xt_ocean = slice(xextent[0] - 0.2,xextent[0] + 0.2),\n",
    "#     yt_ocean = slice(yextent[0] - 0.2,yextent[1] + 0.2)\n",
    "# ).to_netcdf(tmpdir + \"/west_unprocessed\")\n",
    "\n",
    "# om2_input[[\"u\",\"v\",\"salt\",\"temp\",\"eta_t\"]].sel(\n",
    "#     xt_ocean = slice(xextent[0] - 0.2,xextent[1] + 0.2),\n",
    "#     yt_ocean = slice(yextent[1] - 0.2,yextent[1] + 0.2)\n",
    "# ).to_netcdf(tmpdir + \"/north_unprocessed\")\n",
    "\n",
    "# om2_input[[\"u\",\"v\",\"salt\",\"temp\",\"eta_t\"]].sel(\n",
    "#     xt_ocean = slice(xextent[0] - 0.2,xextent[1] + 0.2),\n",
    "#     yt_ocean = slice(yextent[0] - 0.2,yextent[0] + 0.2)\n",
    "# ).to_netcdf(tmpdir + \"/south_unprocessed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seam fixer\n",
    "\n",
    "#1 Identify where the seam is in the dataset. If not between xextent[0] and xextent[1], do nothing.\n",
    "#2 Identify how far seam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asdfasdfa\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "def nicer_slicer(data,xextent,x):\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "xextent = [250,280]\n",
    "\n",
    "hgrid = np.linspace(250,280,20)\n",
    "\n",
    "\n",
    "data = xr.Dataset(\n",
    "    {\"t\":([\"x\"],np.arange(360))},\n",
    "    coords = {\"x\":np.linspace(-270,90,360)}\n",
    ")\n",
    "\n",
    "# data = xr.Dataset(\n",
    "#     {\"t\":([\"x\"],np.arange(360))},\n",
    "#     coords = {\"x\":np.linspace(-180,180,360)}\n",
    "# )\n",
    "\n",
    "\n",
    "seam = data.x[-1].values ## Seam is always positive definined this way\n",
    "\n",
    "mp_target = np.mean(xextent) ## Midpoint of target domain\n",
    "dx = xextent[1] - mp_target\n",
    "\n",
    "\n",
    "## Find a corresponding value for the intended domain midpint in our data. Assuming here that data has equally spaced longitude values spanning 360deg\n",
    "for i in range(-1,2,1):\n",
    "    if (data.x[0] <= mp_target + 360 * i <= data.x[-1]):\n",
    "        _mp_target = mp_target + 360 * i ## Shifted version of target midpoint. eg, could be -90 vs 270\n",
    "\n",
    "\n",
    "        mp_data = data.x[data[x]shape[0]//2].values\n",
    "\n",
    "        shift = (data[x]shape[0] * (_mp_target - mp_data)) // 360\n",
    "        shift = int(shift)\n",
    "\n",
    "        new_data = data.roll(x = -1 * shift,roll_coords=True)   ## Shifts data so that the midpoint of regional domain is in the middle of xarray for easy slicing\n",
    "\n",
    "        new_x = new_data[x]values\n",
    "\n",
    "\n",
    "        ## Take the 'seam' of the data, and either backfill or forward fill based on whether the data was shifted east or west\n",
    "        if shift < 0:\n",
    "            new_seam_index = shift\n",
    "\n",
    "            new_x[0:new_seam_index] += 360\n",
    "\n",
    "        if shift > 0:\n",
    "            new_seam_index = shift\n",
    "\n",
    "            new_x[new_seam_index:] -= 360\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        new_data = new_data.assign_coords({\"x\":new_x})\n",
    "\n",
    "        ## Choose the number of x points to take from the middle, including a buffer. Use this to index the new global dataset\n",
    "\n",
    "        num_xpoints = int(data[x]shape[0]* (mp_target - xextent[0]))// 360 + 8 ## The extra 8 is a buffer region\n",
    "\n",
    "        sliced_data = new_data.isel(x = slice(data[x]shape[0]//2 - num_xpoints,data[x]shape[0]//2 + num_xpoints))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Now we have the right data, but the underlying grid may still be wrong. Need to check the start and end sign values and adjust accordingly\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'h5netcdf', 'scipy', 'cfgrib', 'cfradial1', 'furuno', 'gamic', 'gini', 'iris', 'odim', 'pydap', 'radolan', 'rainbow', 'rasterio', 'wradlib-cfradial1', 'wradlib-cfradial2', 'wradlib-furuno', 'wradlib-gamic', 'wradlib-iris', 'wradlib-odim', 'wradlib-rainbow', 'zarr']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a \u001b[39m=\u001b[39m expt\u001b[39m.\u001b[39;49mocean_forcing(\n\u001b[1;32m      2\u001b[0m     tmpdir,  \u001b[39m## Path to ocean foring files\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m     {\u001b[39m\"\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39myh\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39myt_ocean\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mxh\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mxt_ocean\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m      \u001b[39m\"\u001b[39;49m\u001b[39mxq\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mxu_ocean\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39myq\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39myu_ocean\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m      \u001b[39m\"\u001b[39;49m\u001b[39mzl\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mst_ocean\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39meta\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39meta_t\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mu\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mu\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mv\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m      \u001b[39m\"\u001b[39;49m\u001b[39mtracers\u001b[39;49m\u001b[39m\"\u001b[39;49m:{\u001b[39m\"\u001b[39;49m\u001b[39msalt\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39msalt\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mtemp\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mtemp\u001b[39;49m\u001b[39m\"\u001b[39;49m}},\n\u001b[1;32m      7\u001b[0m     boundaries \u001b[39m=\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39msouth\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mnorth\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mwest\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39meast\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      8\u001b[0m     gridtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mB\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m     )\n",
      "File \u001b[0;32m~/cosima_regional/mom6-regional-scripts/regional_library.py:219\u001b[0m, in \u001b[0;36mexperiment.ocean_forcing\u001b[0;34m(self, path, varnames, boundaries, gridtype, vcoord_type)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39mReads in the forcing files that force the ocean at boundaries (if specified) and for initial condition\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39m    vcoord_type (str)            the type of vertical coordinate used in the forcing files. Either 'height' or 'thickness'.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[39m## Do initial condition\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \n\u001b[1;32m    217\u001b[0m \u001b[39m## pull out the initial velocity on MOM5's Bgrid\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m ic_raw \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39;49mopen_dataset(path \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m/ic_unprocessed\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    221\u001b[0m \u001b[39mif\u001b[39;00m varnames[\u001b[39m\"\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39min\u001b[39;00m ic_raw\u001b[39m.\u001b[39mcoords:\n\u001b[1;32m    222\u001b[0m     ic_raw \u001b[39m=\u001b[39m ic_raw\u001b[39m.\u001b[39misel({varnames[\u001b[39m\"\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m\"\u001b[39m] : \u001b[39m0\u001b[39m})\n",
      "File \u001b[0;32m/g/data/hh5/public/apps/miniconda3/envs/analysis3-22.10/lib/python3.9/site-packages/xarray/backends/api.py:510\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m     kwargs\u001b[39m.\u001b[39mupdate(backend_kwargs)\n\u001b[1;32m    509\u001b[0m \u001b[39mif\u001b[39;00m engine \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 510\u001b[0m     engine \u001b[39m=\u001b[39m plugins\u001b[39m.\u001b[39;49mguess_engine(filename_or_obj)\n\u001b[1;32m    512\u001b[0m backend \u001b[39m=\u001b[39m plugins\u001b[39m.\u001b[39mget_backend(engine)\n\u001b[1;32m    514\u001b[0m decoders \u001b[39m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    515\u001b[0m     decode_cf,\n\u001b[1;32m    516\u001b[0m     open_backend_dataset_parameters\u001b[39m=\u001b[39mbackend\u001b[39m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m     decode_coords\u001b[39m=\u001b[39mdecode_coords,\n\u001b[1;32m    523\u001b[0m )\n",
      "File \u001b[0;32m/g/data/hh5/public/apps/miniconda3/envs/analysis3-22.10/lib/python3.9/site-packages/xarray/backends/plugins.py:177\u001b[0m, in \u001b[0;36mguess_engine\u001b[0;34m(store_spec)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     error_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfound the following matches with the input file in xarray\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms IO \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbackends: \u001b[39m\u001b[39m{\u001b[39;00mcompatible_engines\u001b[39m}\u001b[39;00m\u001b[39m. But their dependencies may not be installed, see:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://docs.xarray.dev/en/stable/user-guide/io.html \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m     )\n\u001b[0;32m--> 177\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'h5netcdf', 'scipy', 'cfgrib', 'cfradial1', 'furuno', 'gamic', 'gini', 'iris', 'odim', 'pydap', 'radolan', 'rainbow', 'rasterio', 'wradlib-cfradial1', 'wradlib-cfradial2', 'wradlib-furuno', 'wradlib-gamic', 'wradlib-iris', 'wradlib-odim', 'wradlib-rainbow', 'zarr']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html"
     ]
    }
   ],
   "source": [
    "a = expt.ocean_forcing(\n",
    "    tmpdir,  ## Path to ocean foring files\n",
    "    {\"time\":\"time\",\"yh\":\"yt_ocean\",\"xh\":\"xt_ocean\",\n",
    "     \"xq\":\"xu_ocean\",\"yq\":\"yu_ocean\",\n",
    "     \"zl\":\"st_ocean\",\"eta\":\"eta_t\",\"u\":\"u\",\"v\":\"v\",\n",
    "     \"tracers\":{\"salt\":\"salt\",\"temp\":\"temp\"}},\n",
    "    boundaries = [\"south\",\"north\",\"west\",\"east\"],\n",
    "    gridtype=\"B\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3]",
   "language": "python",
   "name": "conda-env-analysis3-py"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
